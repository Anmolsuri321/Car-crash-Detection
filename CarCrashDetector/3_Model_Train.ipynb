{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "3_Model_Train.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "dZ4hXXSQPEFh",
        "z1cwXZWXfJ3y",
        "D10eOV4wPnZP",
        "NCfhpvFj9MVS",
        "6pjCRDpOhGLk",
        "JfzW_sWmp39e",
        "ePZgf0VW2weC",
        "RgF4WQC9qtvo",
        "kzOtCDUzX6Aa",
        "HfakcuIMrHXy",
        "P787R4Wj5gve",
        "Fqe2HRtyyoCg",
        "G4q8BO1oXi9f",
        "Xu8zvCO4Hx9n",
        "0n_coMJHvX8i",
        "V489D1fOveaC",
        "mgMfqf-CwFnj",
        "N_RRHvTH3vgw",
        "gkokJ2EXYSfi",
        "bI48GlDZYYjg",
        "gD8NyYXSoCCK"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/Giffy/CarCrashDetector/blob/master/3_Model_Train.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "dZ4hXXSQPEFh",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Index\n",
        "<ol>\n",
        "    <li><a href=\"#system _setup\">System setup</a>\n",
        "    <li><a href=\"#env_dataset\">Environment setup and Dataset overview</a>\n",
        "    <li><a href=\"#GPU_RAM\">Checking RAM available in GPU</a>\n",
        "    <li><a href=\"#model_training\">Model training</a>\n",
        "    <li><a href=\"#model_analysis\">Model analysis</a>\n",
        "    "
      ]
    },
    {
      "metadata": {
        "id": "z1cwXZWXfJ3y",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "<a id=\"system_setup\"> </a>\n",
        "# 1. System setup"
      ]
    },
    {
      "metadata": {
        "id": "D10eOV4wPnZP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 1.1 System info and check"
      ]
    },
    {
      "metadata": {
        "id": "E9_XGk6Gfeu-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "GPU is required to create the model. We start checking if system has a GPU ready\n",
        "\n",
        "Checking if GPU is available.\n",
        "If error message appears, go to 'Runtime' menu in colab and in 'Change runtime type' change the hardware\n",
        "acceleration from None to GPU."
      ]
    },
    {
      "metadata": {
        "id": "TEyu5N0u7GWi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Check if GPU is available\n",
        "import tensorflow as tf\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found, to activate the GPU go to menu \"Runtime\" and submenu \"Change runtime type\", then change hardware accelerator from None to GPU.')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NCfhpvFj9MVS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 1.2 Link Goggle Drive with Colab \n",
        "\n",
        "Run the code and follow the link to get an authentification key, copy it and paste in the box that will appear in jupyter notebook.  After fist key the script will ask for a second authentification key, follow the process as above. \n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "DkHETrDoHZaE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Check is Link to Drive is OK\n",
        "google = !if [ -d 'mydrive/' ]; then echo \"1\" ; else echo \"0\"; fi\n",
        "if (google[0] is '0' ):\n",
        "  from google.colab import drive\n",
        "  drive.mount('/content/mydrive')\n",
        "!if [ -d 'mydrive/' ]; then echo \"Connection to Google drive successful\" ; else echo \"Error to connect to Google drive\"; fi"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "K4bzHQCYqYy7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#!kill -9 -1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6pjCRDpOhGLk",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 1.3 Install and update python libraries\n",
        "Set up of Python, installing the required modules\n",
        "<ol>\n",
        "   <li>Updated python package manager (pip)\n",
        "   <li>Torchvision\n",
        "   <li>Pillow 4.0.0 (required for fastai library)\n",
        "   <li>Image\n",
        "   <li>Fast ai\n"
      ]
    },
    {
      "metadata": {
        "id": "Tayh7BBEfYGK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip install --upgrade pip  > /dev/null\n",
        "!pip install scipy==1.0.0 > /dev/null\n",
        "!pip install http://download.pytorch.org/whl/cu75/torch-0.3.0.post4-cp36-cp36m-linux_x86_64.whl  && pip install torchvision\n",
        "#!pip install Pillow==4.0.0 > /dev/null\n",
        "!pip install Pillow==4.1.1 > /dev/null\n",
        "#!pip install PIL  > /dev/null\n",
        "!pip install image  > /dev/null\n",
        "!pip install fastai==0.7.0  > /dev/null\n",
        "!apt update && apt install -y libsm6 libxext6 > /dev/null"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JfzW_sWmp39e",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "<a id=\"env_dataset\"> </a>\n",
        "# 2. Environment setup & dataset overview"
      ]
    },
    {
      "metadata": {
        "id": "ePZgf0VW2weC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 2.1 Dataset location and folder check / creation\n",
        "Define the dataset location path\n"
      ]
    },
    {
      "metadata": {
        "id": "m3RERGKc29Iu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "PATH = \"mydrive/CarCrashDetection/Dataset/\"\n",
        "!if [ -d 'mydrive/CarCrashDetection/Dataset/models' ]; then echo \"Directory models already exist\" ; else mkdir '!mkdir mydrive/CarCrashDetection/Dataset/models' && echo \"Directory models created\"; fi\n",
        "!ls {PATH}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Xfisv1ZefKnp",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "```\n",
        "./dataset    \n",
        "│\n",
        "└─── models\n",
        "│\n",
        "└─── train      (80% of supervised image set)\n",
        "│   └─  accident\n",
        "│   │    └─ frame001.jpg\n",
        "│   │       frame009.jpg\n",
        "│   └─  no_accident\n",
        "│        └─ frame006.jpg\n",
        "│           frame052.jpg\n",
        "│\n",
        "└─── valid     (20% of supervised image set)\n",
        "     └─  accident\n",
        "     │    └─ frame041.jpg\n",
        "     │       frame037.jpg\n",
        "     └─  no_accident\n",
        "          └─ frame025.jpg\n",
        "             frame068.jpg\n",
        "\n",
        "```"
      ]
    },
    {
      "metadata": {
        "id": "RgF4WQC9qtvo",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 2.2 Dataset overview\n",
        "Quick check of dataset\n",
        "### Number of training examples by categories"
      ]
    },
    {
      "metadata": {
        "id": "umVXBVV3sT_C",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "valid_accident = !ls {PATH}valid/accident \n",
        "valid_no_accident = !ls {PATH}valid/no_accident\n",
        "train_accident = !ls {PATH}train/accident\n",
        "train_no_accident = !ls {PATH}train/no_accident\n",
        "\n",
        "print(f\"Number of valid images with accident: {len(valid_accident)}\")\n",
        "print(f\"Number of valid images with no_accident: {len(valid_no_accident)}\")\n",
        "print(f\"Number of train images with accident: {len(train_accident)}\")\n",
        "print(f\"Number of train images with no_accident: {len(train_no_accident)}\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kzOtCDUzX6Aa",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 2.3 Quick look a no_accident image"
      ]
    },
    {
      "metadata": {
        "id": "Jr9vBFxh3apG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "files = !ls {PATH}valid/no_accident | head\n",
        "img = plt.imread(f'{PATH}valid/no_accident/{files[5]}')\n",
        "plt.imshow(img);\n",
        "img.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HfakcuIMrHXy",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "<a id=\"GPU_RAM\"> </a>\n",
        "# 3. Checking RAM available in GPU"
      ]
    },
    {
      "metadata": {
        "id": "P787R4Wj5gve",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 3.1 Checking system configuration and RAM memory available\n",
        "The system should have enough RAM to create the model, let's go to check it."
      ]
    },
    {
      "metadata": {
        "id": "Y961g8x-311-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# memory footprint support libraries/code\n",
        "!ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi\n",
        "!pip install gputil  > /dev/null\n",
        "!pip install psutil  > /dev/null\n",
        "!pip install humanize  > /dev/null"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JCylTU9XHJbk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import psutil\n",
        "import humanize\n",
        "import os\n",
        "import GPUtil as GPU"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6yJnElXC342M",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "GPUs = GPU.getGPUs()\n",
        "# XXX: only one GPU on Colab and isn't guaranteed\n",
        "gpu = GPUs[0]\n",
        "\n",
        "def printm():\n",
        "  process = psutil.Process(os.getpid())\n",
        "  print(\"Gen RAM Free: \" + humanize.naturalsize( psutil.virtual_memory().available ), \" I Proc size: \" + humanize.naturalsize( process.memory_info().rss))\n",
        "  print('GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total {3:.0f}MB'.format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))\n",
        "printm()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Fqe2HRtyyoCg",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 3.2 If GPU RAM free is lower than 600Mb, uncomment  ! pkill python3"
      ]
    },
    {
      "metadata": {
        "id": "LKdCqBYAyiMs",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#@title\n",
        "# Uncomment the below if you need to reset GPU to recover RAM\n",
        "! pkill python3"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "G4q8BO1oXi9f",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "<a id=\"model_training\"> </a>\n",
        "# 4. Model training"
      ]
    },
    {
      "metadata": {
        "id": "17n4gl6ivC7c",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Building a successful neural network is an iterative process. We shouldn't expect to come up with a magical idea that will make a great network from the start. "
      ]
    },
    {
      "metadata": {
        "id": "iPU3okrr3ram",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Uncomment the below if you need to reset your precomputed activations\n",
        "#!rm -rf {PATH}tmp"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Xu8zvCO4Hx9n",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 4.1 Load libraries\n",
        "Import the fastai library"
      ]
    },
    {
      "metadata": {
        "id": "x40GwEVkzF0k",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Put these at the top of every notebook, to get automatic reloading and inline plotting\n",
        "%reload_ext autoreload\n",
        "%autoreload 2\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qVlyBw8yzHNz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# This file contains all the main libs we'll use\n",
        "from fastai.imports import *\n",
        "from fastai.transforms import *\n",
        "from fastai.conv_learner import *\n",
        "from fastai.model import *\n",
        "from fastai.dataset import *\n",
        "from fastai.sgdr import *\n",
        "from fastai.plots import *"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zDyv5WT3xv05",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "PATH = \"mydrive/CarCrashDetection/Dataset/\"      # Use the same PATH than Environment Setup"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0n_coMJHvX8i",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 4.2  Architecture\n",
        "The chosen architecture is resnet34, it comes pretrained with a huge imagenet dataset and it's not too complex."
      ]
    },
    {
      "metadata": {
        "id": "JINcvZNIvkHo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "arch = resnet34"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "V489D1fOveaC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 4.3  Size\n",
        "Resnet34 was trained on mostly 224·224 to 299·299 images sizes. For that reason, transforming the training images to that size should result in decent result.\n",
        "\n",
        "-  Size can be reduced to minimize that the resnet will runtime error on Colab due to gpu memory shortage"
      ]
    },
    {
      "metadata": {
        "id": "tsslJTftvuoa",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "size = 299"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mgMfqf-CwFnj",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 4.4 Batch size\n",
        "Batch size defines how many images we take to compute the approximated gradient for stochastic gradient descent.<br>\n",
        "If it's too big it will take a long time to converge and if it's to small the predictions won't be precise enough and it may not converge.<br>\n",
        "For what I've seen, 64 seems like a reasonable choice."
      ]
    },
    {
      "metadata": {
        "id": "2MTb_i3RwOsy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "batch_size = 60"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "N_RRHvTH3vgw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 4.5 Image classification with Convolutional Neural Networks\n"
      ]
    },
    {
      "metadata": {
        "id": "iLtFUi5u3-qC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "data = ImageClassifierData.from_paths(PATH, tfms=tfms_from_model(arch, size), bs=batch_size)\n",
        "try:\n",
        "  learn = ConvLearner.pretrained(arch, data, precompute=True)                   # Colab generates a \"runtime error due to gpu memory shortage\" and pretrain can not finalize\n",
        "except:\n",
        "  learn = ConvLearner.pretrained(arch, data, precompute=True)                   # Launched again, it will continue and will finalize pretrain properly\n",
        "\n",
        "## If error pops up, run again this line again. It's probably due to long processing time required or gpu memory shortage."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gkokJ2EXYSfi",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 4.6 Model creation"
      ]
    },
    {
      "metadata": {
        "id": "uEWpE65jOzfB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "epoch = 5\n",
        "learn.fit(0.01, epoch )\n",
        "\n",
        "import time\n",
        "hora = time.strftime(\"%y%m%d-%H%M\")\n",
        "print (\"Size = \" + str(size))\n",
        "print (\"Batch size = \" + str(batch_size))\n",
        "model_name = \"carCrash\" + hora +\"_sz\"+str(size)+\"_bs\"+str(batch_size)+\"_ep\"+str(epoch)\n",
        "print (\"Saving model as:\", model_name, \".h5\")\n",
        "learn.save(model_name)\n",
        "print (\"Model saved successfully\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bI48GlDZYYjg",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "<a id=\"model_analysis\"> </a>\n",
        "# 5. Model analysis"
      ]
    },
    {
      "metadata": {
        "id": "ekGxdhXU4GxO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# This is the label for a val data\n",
        "data.val_y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tPy0mm1-PJbs",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# from here we know that 'accident' is label 0 and 'no_accident' is label 1.\n",
        "data.classes"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5Aaz4kpmQxuc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# this gives prediction for validation set. Predictions are in log scale\n",
        "log_preds = learn.predict()\n",
        "log_preds.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7VvERJ6DZTCC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "log_preds[:10]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nlKPjJSqZUMk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "preds = np.argmax(log_preds, axis=1)  # from log probabilities to 0 or 1\n",
        "probs = np.exp(log_preds[:,1])        # pr(no_accident)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Jpk5zOBdZWec",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def rand_by_mask(mask): return np.random.choice(np.where(mask)[0], 4, replace=False)\n",
        "def rand_by_correct(is_correct): return rand_by_mask((preds == data.val_y)==is_correct)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "aX01xucEZZlS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def plot_val_with_title(idxs, title):\n",
        "    imgs = np.stack([data.val_ds[x][0] for x in idxs])\n",
        "    title_probs = [probs[x] for x in idxs]\n",
        "    print(title)\n",
        "    return plots(data.val_ds.denorm(imgs), rows=1, titles=title_probs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rS5uJhokZcNK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def plots(ims, figsize=(12,6), rows=1, titles=None):\n",
        "    f = plt.figure(figsize=figsize)\n",
        "    for i in range(len(ims)):\n",
        "        sp = f.add_subplot(rows, len(ims)//rows, i+1)\n",
        "        sp.axis('Off')\n",
        "        if titles is not None: sp.set_title(titles[i], fontsize=16)\n",
        "        plt.imshow(ims[i])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "V--LnF5HZelw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def load_img_id(ds, idx): return np.array(PIL.Image.open(PATH+ds.fnames[idx]))\n",
        "\n",
        "def plot_val_with_title(idxs, title):\n",
        "    imgs = [load_img_id(data.val_ds,x) for x in idxs]\n",
        "    title_probs = [probs[x] for x in idxs]\n",
        "    print(title)\n",
        "    return plots(imgs, rows=1, titles=title_probs, figsize=(16,8))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_9SYmNw5Zir0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# 1. A few correct labels at random\n",
        "plot_val_with_title(rand_by_correct(True), \"Correctly classified\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "k968LFRPZlXA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# 2. A few incorrect labels at random\n",
        "plot_val_with_title(rand_by_correct(False), \"Incorrectly classified\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "b7LzGBFaZU5T",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# 3. A few no accident labels at random\n",
        "most_by_correct_no_accident = np.argsort(np.abs(probs -1))[:4]\n",
        "plot_val_with_title(most_by_correct_no_accident, \"No accidents\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lZvX7u9XZyJH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# 4. A few accident labels at random\n",
        "most_by_correct_accident = np.argsort(np.abs(probs -0))[:4]\n",
        "plot_val_with_title(most_by_correct_accident, \"accidents\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "h_pmKTLtnlSW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# 5. A few uncertain labels at random\n",
        "most_uncertain = np.argsort(np.abs(probs -0.5))[:4]\n",
        "plot_val_with_title(most_uncertain, \"Most uncertain predictions\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0nRB8u95nmc-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "learn = ConvLearner.pretrained(arch, data, precompute=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FxQ52v7lnzAO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "lrf=learn.lr_find()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "I1-kQZUFn1rs",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "learn.sched.plot_lr()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_MqDdtFDn4Gy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "learn.sched.plot()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gD8NyYXSoCCK",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Analyzing results: loss and accuracy"
      ]
    },
    {
      "metadata": {
        "id": "qDV7O4nBn8t0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def binary_loss(y, p):\n",
        "    return np.mean(-(y * np.log(p) + (1-y)*np.log(1-p)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "EtNQ7UvtoJIg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "acts = np.array([1, 0, 0, 1])\n",
        "preds = np.array([0.9, 0.1, 0.2, 0.8])\n",
        "binary_loss(acts, preds)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
